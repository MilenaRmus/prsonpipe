#!/bin/bash
#
# preprocess runs the preprocessing steps
#
# This script was inspired by NeuroPipe. 
################################################################################----------
# Packages used:
#  none
# Files sourced:
#  globals.par
#  funcs
# Arguments:
#  none 	: will run all tasks with all NEW subjects (on a task by task basis)
#  TSK		: will run tasks listed before subids, if exists (must be first arguments)
#  [subs] 	: subject array -- e.g. (1 {3..5}); "${var[@]}"; s001 02 s005; 'all'
################################################################################----------

set -e # stop immediately when an error occurs

label='[PREP]'

# load settings and functions
source globals.par

pushd ${SCRIPT_DIR_UTIL} > /dev/null
source funcs
first_jobid=1
#first_jobid=$(sbatch first_job | grep -o '[0-9]*')
popd > /dev/null

if [[ $1 == "no-convert" ]]; then shift; else 
# CONVERT NEW DATA
# Convert new subject data from arch/dicom/*tar.gz to raw/TSK/s000/*nii.gz
convert_log=${PROJECT_DIR}/auxil/archive/LOG_convert.txt
echo "${label} $(date) -- Converting all dcm files to nii ---" | tee -a "${convert_log}"
pushd ${SCRIPT_DIR_UTIL} > /dev/null
bash run_convert
popd > /dev/null
wait_for_it '[CONVERT]' $convert_log
fi

# DETERMINE WHICH TASKS TO RUN
# if one or more input argument, check if first is task name.  
if [[ $# -ge 1 ]] && [[ -d ${RAW_DIR}/${1} ]]; then 
	# If so, start making list of tasks to run
	TASKS=(${1}); shift;
	# check other arguments until you get to one that is not a task
	while [[ $# -ge 1 ]]; do
		# If arg is task name, add to task list and shift to next arg
		if [[ -d ${RAW_DIR}/${1} ]]; then TASKS=("${TASKS[@]}" ${1}); shift; 
                else break; 
                fi
	done
fi
echo "${label} Running task(s): ${TASKS[@]}"; 

# RUN TASKS
for t in "${TASKS[@]}"; do 
	echo "${label}"
	echo "${label} $(date) >>> Starting task $t <<<"

	# GET PARAMETERS
	# source task's pars file
	if [[ $PREP_SEP -eq 0 ]]; then parsfile=pars.par; else parsfile=pars_${t}.par; fi
	source ${PARS_DIR}/${parsfile}

	# make sure that all steps are correct
	# DARTEL: must run normalization, if used at all, if r used, then u='none'
	# FSL: if u=FSL, then r=FSL
	# SPM12w: if w=SPM12w, then r=SPM12w
	i=0
	for p in "${step_softs[@]}"; do
		step_name=${step_names[$i]}
		# check if $p is a valid software
		snum=0
		if [[ $p != 'none' ]]; then
			for s in "${PREP_SOFTS[@]}"; do 
				if [[ $s == $p ]]; then break; fi
				snum=$((${snum} + 1))
			done
			if [[ ${snum} -eq ${#PREP_SOFTS[@]} ]]; then
				echo "${label} ERROR: ${step_name}=$p is not a valid \
					software choice. Each step must be set to one of \
					the following: none ${PREP_SOFTS[@]}";
				exit
			fi
		fi
		# DARTEL
		if [[ $p == ${DARTEL} ]]; then 
			if [[ ${NORM} != ${DARTEL} ]]; then
				echo "${label} ERROR: ${step_name}=${p} but NORM=${NORM}.\
				 In ${DARTEL}, NORM must always be used. Aborting...";
				exit
			fi
			if [[ ${REALIGN} == ${DARTEL} ]] && [[ ${UNWARP} != 'none' ]]; 
			then echo "${label} ERROR: ${step_name}=${p} but UNWARP=${UNWARP}\
			. In ${DARTEL}, if REALIGN is used, then UNWARP must be set to \
			'none'. Aborting..."
			exit
			fi
		fi
		i=$(($i + 1))
	done
	# FSL
	if [[ ${UNWARP} == ${FSL} ]] && [[ ${REALIGN} != ${FSL} ]]; then 
		echo "${label} ERROR: UNWARP=${UNWARP} but REALIGN=${REALIGN}. In ${FSL},\
			 if UNWARP is used, then REALIGN must be as well. Aborting..."
		exit
	fi
	# SPM12w
	if [[ ${NORM} == ${SPMW} ]] && [[ ${REALIGN} != ${SPMW} ]]; then 
		echo "${label} ERROR: NORM=${NORM} but REALIGN=${REALIGN}. In ${SPMW}, if\
			 NORM is used, then REALIGN must be as well. Aborting..."
		exit
	fi


	# STORE PATH/FILE NAMES
	wd_dir_full=${PREP_DIR}/${t}/${wd_dir}
	stepfile=${PARS_DIR}/step.par
	logfile=${wd_dir_full}/LOG.txt
	logfile_wd=${logfile}
	
	# CREATE WORKING DIRECTORY IN PREP
	if [[ ! -d ${wd_dir_full} ]]; then mkdir ${wd_dir_full}; fi
	DATE=`date +%Y%m%d`
	cp ${PARS_DIR}/${parsfile} ${wd_dir_full}/${DATE}_${parsfile}


	# Create array based on order of used preprocessing software, such that:
	# 0 means the parameter uses a different software than the previous step
	# 1 means the parameter uses the same software as the previous step
	i=0; for p in "${step_softs[@]}"; do
		# check if current step is same as cur_soft (current software parameter)
		if [[ $p != 'none' ]]; then 
			if [[ $p == $cur_soft ]]; then sim_array[$i]=1; 
			else sim_array[$i]=0; 
			fi; 
			cur_soft=$p; 
		else 
			sim_array[$i]=1; 
		fi
		i=$(($i + 1))
	done
	i=0; for p in "${step_softs[@]}"; do 
		if [[ $p != 'none' ]]; then sim_array[$i]=1; break; fi; 
		i=$(($i + 1)); 
	done

	# CREATE LIST OF SUBJECT IDS
	# call get_subs function
	rawdir=raw/$t
	prepdir=prep/${t}/${wd_dir}

	declare -a subs_array=( "$@" )
	get_subs ${rawdir} ${prepdir} "${subs_array[@]}"

	if [[ -z $SUBS ]]; then 
		echo "${label} No subjects found for task $t. Moving on to next task..."; 
		continue; 
	fi

	# LIST STEPS THAT WILL BE RUN AND SAVE THEM TO THE TASK'S LOG FILE
	echo "${label}" | tee -a "$logfile_wd"
	echo "${label} $(date) *** Running subjects ${SUBS[@]} in task $t ***" | tee -a \
		"$logfile_wd"
	echo "${label} Slice Time Correction = $SLICE_TIME" | tee -a "$logfile_wd"
	echo "${label} Motion Correction     = $REALIGN" | tee -a "$logfile_wd"
	echo "${label} Unwarping             = $UNWARP" | tee -a "$logfile_wd"
	echo "${label} Normalization         = $NORM" | tee -a "$logfile_wd"
	echo "${label} Smoothing             = $SMOOTH_SOFT (kernel size: $SMOOTH)" | \
		tee -a "$logfile_wd"
	echo "${label}"
	echo "${label} Writing prep files to ${wd_dir_full}"
	
	# RUN SUBJECTS
	# Run each subject, one at a time
	n=0; for s in "${SUBS[@]}"; do
		echo "${label}"
		echo "${label} $(date) == beginning preprocessing of $s =="

		# CHECK IF SUBJ EXIST IN TSK
		# if subject does not exist, then exit
		if [[ -z $s ]]; then 
			echo "${label} Can't find subject ${s}. Aborting...";
			exit; 
		fi

		first_step=1; prev_jobid=${first_jobid}

		# STORE FILENAMES/PATHS FOR SUBJ
		wd_dir_sub=${wd_dir_full}/${s}

		# SET UP SUBJ FOLDER IN PREP
		# copy sub folder from raw/tsk to prep/tsk/wd
		if [[ -d "${wd_dir_sub}" ]]; then 
			echo "${label} $(date) ${wd_dir_sub} already exists. Deleting..."\
				 | tee -a "$logfile_wd"; rm -rf ${wd_dir_sub}; 
		fi
		echo "${label} $(date) Copying ${s}'s raw folder to ${wd_dir_sub}..." | \
			tee -a "$logfile_wd"
		cp -r ${RAW_DIR}/${t}/${s} ${wd_dir_sub}

		# START LOGFILE
		logfile=${wd_dir_sub}/LOG.txt

		# empty all variables to start new with this subject
		reset_step_par; unset ext; unset pnames

		# GO THROUGH STEPS
		i=0; for p in "${step_softs[@]}"; do

			# SET UP PREPROCESING STEPS
			step_name=${step_names[$i]}; e=${step_exts[$i]}
			# if current step is set to 'none', skip and move on to next step
			if [[ $p != 'none' ]]; then 

				# check if current step NORM in DARTEL
				if [[ ${step_name} == 'NORM' ]] && [[ $NORM == ${DARTEL} ]]; then 
					# if not last subject, reset step par and ext
					if [[ $n -ne $((${#SUBS[@]} - 1)) ]]; then 
						reset_step_par; unset ext; 
					fi; 
					continue; 
				fi

				# add step extension to current software's extension list
				ext=${ext}${e}
				cur_soft=${p}
				pnames="${pnames} ${step_name}"

				# turn on step in step.par
				echo "${step_name}='${cur_soft}'" >> "$stepfile"
				echo "EPI_ACCEL=${EPI_ACCEL}" >> "$stepfile"
				echo "EPI_ECHOSPACING=${EPI_ECHOSPACING}" >> "$stepfile"
			fi

			# check if next step uses same software, if so, run steps
			if [[ ${sim_array[$((${i} + 1))]} -eq 0 ]]; then 

				# RUN STEP(S)

				# if all steps were set to none, skip to next task
				if [[ -z ${pnames} ]]; then  
					echo "${label} All steps set to 'none'. Moving \
						on to next task..."
					echo "${label} WARNING: All steps set to 'none'"\
						 | tee -a "$logfile_wd"
					break 2
				fi

				# WRITE P_FILE
				# if first subject, write out pfile based on step.par
				if [[ $n -eq 0 ]]; then 
					bash ${SCRIPT_DIR_UTIL}/write_pfile \
						${cur_soft} ${t} ${ext}
				fi
				script_path="${SCRIPT_DIR}/${cur_soft}"
				run_script="${script_path}/sbatch_${cur_soft}_prep"
				pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

				# RUN STEP/SUBMIT JOB

				# set run_time
				run_time=$((60 * ${#ext} + 500))
				# add an hour run if normalization is selected
				if [[ ${ext[@]} =~ w ]]; then
					add_time=$((60*$RUNS)) 
					run_time=$((${run_time}+${add_time}))
				fi

				# make run_name for job
				run_name="${cur_soft}${ext}_prep_${s}"

				# move into software's script directory, quietly
				pushd ${script_path} > /dev/null   

				# submit job
				j='%j'
				tflag='-t=${run_time}'
				jflag="-J ${run_name}"
				mflag="--mail-user=${USER_EMAIL}"
				oflag="--output=${OUT_DIR}/${run_name}-$j.out"
				dflag="--dependency=afterok:${prev_jobid}"
				flags="${!tflag} $oflag $jflag $mflag $dflag"
				prev_jobid=$(sbatch $flags "${run_script}" -p "$pfile" "$s" | grep -o '[0-9]*')
				# save/print jobid number
				jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames} in ${cur_soft} for subject ${s}"
				echo "${jobinfo_str}" | tee -a "${logfile_wd}"
				
				# Append job ID to list of job IDs DARTEL has to wait for
				all_jobs+=":${prev_jobid}"

				# return to the previous directory, quietly
				popd > /dev/null   

				# clear variables for next step
				reset_step_par; unset ext; first_step=0; unset pnames;
			fi
			# increase step index by one
			i=$(($i + 1))
		done
		# increase sub index by one
		n=$(($n + 1))
	done
	# setup dependency flag for DARTEL
	unset dependency_flag
	all_jobs=${all_jobs#:} # remove the leading : from all_jobs list for sbatch
	if [[ -n $all_jobs ]]; then 
		dependency_flag="--dependency=afterok:${all_jobs}"
	fi 

	# DARTEL
	# if normalization is run in DARTEL, run group
	if [[ $NORM == ${DARTEL} ]]; then
		echo "${label}"
		echo "${label} $(date) == beginning group preprocessing of ${SUBS[@]} =="

		# SET UP FOR DARTEL

		# set i to NORM index (second to last)
		i=$((${#step_softs[@]} - 2))  

		# store vars
		p=${step_softs[$i]}; step_name=${step_names[$i]}; e=${step_exts[$i]}

		# add step extension to current ext list and turn step on in step.par
		ext=${ext}${e}; cur_soft=${p}; pnames="${pnames} ${step_name}"
		echo "${step_name}='${p}'" >> "$stepfile"

		# if smoothing also uses DARTEL, add s to ext and turn on in step.par
		i=$(($i + 1)); 
		if [[ ${sim_array[$i]} -eq 1 ]] && [[ ${step_softs[$i]} != 'none' ]]; then
			step_name=${step_names[$i]}; e=${step_exts[$i]}; 
			ext=${ext}${e}; pnames="${pnames} $step_name"
			echo "${step_name}='$p'" >> "$stepfile"
		fi

		# RUN DARTEL

		# if few than 20 subs, DARTEL run_time = 48 hours, else run_time=72hrs
		if [[ ${#SUBS[@]} -le 20 ]]; then run_time=2880; else run_time=4320; fi

		# write pfile for DARETL
		bash ${SCRIPT_DIR_UTIL}/write_pfile ${cur_soft} ${t} ${ext}

		# path names
		script_path="${SCRIPT_DIR}/${cur_soft}"
		run_script="${script_path}/sbatch_${cur_soft}_prep"
		pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

		# make run_name for job
		run_name="${cur_soft}${ext}_prep"

		# move into software's script directory, quietly
		pushd ${script_path} > /dev/null   	

		# submit job
		tflag='-t ${run_time}'
                jflag="-J ${run_name}"
                mflag="--mail-user=${USER_EMAIL}"
                dflag="--dependency=afterok:${prev_jobid}"
		oflag="-o ${OUT_DIR}/${run_name}-%j.out"
		flags="${!tflag} $oflag $jflag $mflag $dflag"
                prev_jobid=$(sbatch ${flags} "${run_script}" -p "$pfile" ${SUBS[@]} | grep -o '[0-9]*')

		# print jobid to console
		jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames} in ${cur_soft} for subject(s) ${SUBS[@]}"
		echo ${jobinfo_str}

		# write to each sub's logfiles
		for s in "${SUBS[@]}"; do
			logfile=${wd_dir_full}/${s}/LOG.txt
			echo "${jobinfo_str}" >> "${logfile}"
		done

		# return to the previous directory, quietly
		popd > /dev/null

		# RUN SMOOTHING (iff not in DARTEL)
		if [[ ${sim_array[$i]} -eq 0 ]]; then
			n=0; for s in "${SUBS[@]}"; do
				echo "${label}"

				# unset variables
				reset_step_par; unset ext; unset pnames

				# assign variables for this step
				p=${step_softs[$i]}
				step_name=${step_names[$i]} 
				e=${step_exts[$i]}
				ext=${ext}${e}
				cur_soft=$p
				pnames="${pnames} $step_name"

				# write step to step pars file
				echo "${step_name}='$p'" >> "$stepfile"

				# subject's log file
				logfile=${wd_dir_full}/${s}/LOG.txt

				# if first subject, write out pfile based on step.par
				if [[ $n -eq 0 ]]; then 
					bash ${SCRIPT_DIR_UTIL}/write_pfile \
						${cur_soft} ${t} ${ext}
				fi

				# set paths to scripts/pfile for job
				script_path="${SCRIPT_DIR}/${cur_soft}"
				run_script="${script_path}/sbatch_${cur_soft}_prep"
				pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

				# make run_name for job
                		run_name="${cur_soft}${ext}_prep_${s}"

				# run job
				pushd ${script_path} > /dev/null
				tflag='-t 60'
				jflag="-J ${run_name}"
				mflag="--mail-user=${USER_EMAIL}"
				oflag="-o ${OUT_DIR}/${run_name}-%j.out"
				dflag="--dependency=afterok:${prev_jobid}"
				flags="${!tflag} $oflag $jflag $mflag $dflag"
		                prev_jobid=$(sbatch ${flags} "${run_script}" -p "$pfile" "${s}" | grep -o '[0-9]*')
				jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames} in ${cur_soft} for subject ${s}"
				echo "${jobinfo_str}" | tee -a "${logfile_wd}"
				popd > /dev/null

				# increase sub index by one
				n=$(($n + 1))
			done
		fi
	fi

	# Write '[PREP] Done.' in each subject's LOG.txt file
	for s in "${SUBS[@]}"; do
		# iff the subject's folder exists
		if [[ -d ${wd_dir_full}/${s} ]]; then
			logfile=${wd_dir_full}/${s}/LOG.txt
			echo "${label} Done. $(date)" >> "$logfile"
		fi
	done

	# Write Done. to task logifle
	echo "${label}" | tee -a "${logfile_wd}"
	echo "${label} Done. $(date)" | tee -a "${logfile_wd}"
	echo "${label}" >> "${logfile_wd}"
done

