#!/bin/bash
#
# June 21, 2017: Miriam Weaverdyck added flags and style standards.
# run_prep reads in prep_TSK.par or prep.par pfiles and launches each of the 
# steps as efficiently as possible. Sequential steps that use the same software
# will be run together. Every subject is run separately, unless group normalization
# in DARTEL is turned on.
#
################################################################################----------
# Packages used:
#  matlab
#
# Files sourced:
#  globals.par
#  funcs
#  prep.par (or prep_TSK.par)
#
# Flags:
#  [-h]         : help
#  [-c]         : skip conversion
#  [-t]         : task
#  [-p]         : pfile to be sourced (default = prep.par or prep_TSK.par)
#  [-d] 		: dependency jobIDs (e.g. 1111111:2222222:3333333)
#
# Arguments:
#  [subs] 	: subjects to run
#
###############################################################################----------

set -e
label='[PREP]'

######################### SOURCE FILES ########################################
# Get the name of the directory this script is in to create full path to globals.par
d="$(dirname -- "$(pwd)")"
# source globals.par
source "${d%scripts*}/scripts/globals.par"
# source functions
source ${SCRIPT_DIR_UTIL}/funcs

convert=true
keep_prep=false

######################### SET UP & PARSE ARGUMENTS #############################
function help_func () {
cat << END
  sbatch_SPM12w_prep [-piold]
  Description:
  ------------
	Launches preprocessing steps for each subject based on 
	specified parameters in prep.par
  Usage:
  ------
	[<subs>]
	  Subjects to run
	  Keywords: 'all', 'new'
	[-h | --help | -help]
	  Display this help
	[-c]
	  Skip conversion
	[-t <TSK>]
	  Run task 'TSK' only (default runs all). 
	  Valid tasks: ${TASKS[@]}
	[-a <prepdir>]
	  Does NOT overwrite previously preprocessed data. Uses epi_r##.nii.gz files in 
	  ${PREP_DIR}/<TSK>/<prepdir> as raw and runs all steps in pfile on those files
	[-p <filename>]
	  filename of pfile (default is 'prep.par' or 'prep_TSK.par')
	[-d <jobIDs>]
	  jobIDs that these jobs will be dependent on. 
	  Valid form: 1111111:2222222:3333333
END
}
#First, check for help flag (multi-character flags not supported by getopts)
if [[ $@ =~ -h|--help|-help ]]; then help_func; exit; fi

#Parse flags other than help
while getopts "ct:p:d:a:" opt; do
  case $opt in
    p)
      pfile=${PARS_DIR}/$(basename $OPTARG)
      if [ ! -f $pfile ]; then
        echo "$label ERROR: pfile $pfile does not exist. Use -h for help."
        exit 1
      fi
      echo "$label Using pfile: $pfile"
      ;;
    c)
      convert=false
      echo "$label Skipping conversion."
      ;;
    t)
      tasks=$OPTARG
      if ! $(isTSK $tasks); then
      	echo "$label ERROR: $tasks is not a valid task. Use -h for help."
      	exit 1
      fi
      echo "$label Inputted task: $tasks"
      ;;
    d)
      jobIDs=$OPTARG
      if $(isNUM ${jobIDs:0}); then
        first_jobid=$jobIDs
      else
        echo "${label} ERROR: $jobIDs is not a valid dependency arg. Use -h for help."
        exit 1
      fi
      ;;
    a)
      keep_prep=true
      prev_wd_dir=$OPTARG
      dname=${PREP_DIR}/*/${prev_wd_dir}
      if ! $(isDIR ${dname}); then
      	echo "${label} ERROR: ${dname} is not a valid directory. Use -h for help."
      	exit 1
      fi
      echo "$label Using ${prev_wd_dir} as prep directory. WARNING: Using preprocessed data, not raw."
      ;;
    \?)
      echo "$label ERROR: unknown flag specified: ${opt}. Use -h for help."
      exit 1
      ;;
    : ) #Catch options without arguments
      echo "$label ERROR: -$OPTARG requires an argument. Use -h for help."
      exit 1
    esac
done
#remove used input args
shift $((OPTIND -1))

[[ -z $first_jobid ]] && first_jobid=1

mflag="--mail-user=${USER_EMAIL}"
script_path="${PARS_DIR}"

# CONVERT NEW DATA
if ${convert}; then
	# Convert new subject data from arch/dicom/*tar.gz to raw/TSK/s000/*nii.gz
	convert_log=${PROJECT_DIR}/auxil/archive/LOG_convert.txt
	echo "$label $(date) -- Converting all dcm files to nii --" | tee -a "${convert_log}"
	pushd ${SCRIPT_DIR_UTIL} > /dev/null
	bash ${SCRIPT_DIR_UTIL}/run_convert
	popd > /dev/null
	wait_for_it '[CONVERT]' $convert_log
fi

# SELECT TASKS
[[ -z $tasks ]] && tasks=( "${TASKS[@]}" )
echo "${label} Running task(s): ${tasks[@]}"; 

# CYCLE THROUGH EACH TASK
for t in "${tasks[@]}"; do 
	echo "${label}"
	echo "${label} $(date) >>> Starting task $t <<<"

	# GET PARAMETERS
	# source task's prep.par file
	if [[ $PREP_SEP -eq 0 ]]; then parsfile=prep.par; else parsfile=prep_${t}.par; fi
	source ${PARS_DIR}/${parsfile}

	# PATH/FILE NAMES
	[[ ! -z ${prev_wd_dir} ]] && wd_dir=${prev_wd_dir} 
	wd_dir_full=${PREP_DIR}/${t}/${wd_dir}
	stepfile=${PARS_DIR}/step.par
	logfile=${wd_dir_full}/LOG.txt
	logfile_wd=${logfile}

	# make sure that all steps are correct
	# DARTEL: must run normalization, if used at all, if r used, then u='none'
	# FSL: if u=FSL, then r=FSL
	# SPM12w: if w=SPM12w, then r=SPM12w
	i=0
	for p in "${step_softs[@]}"; do
		step_name=${step_names[$i]}
		# check if $p is a valid software
		snum=0
		if [[ $p != 'none' ]]; then
			for s in "${PREP_SOFTS[@]}"; do 
				if [[ $s == $p ]]; then break; fi
				snum=$((${snum} + 1))
			done
			if [[ ${snum} -eq ${#PREP_SOFTS[@]} ]]; then
				echo "${label} ERROR: ${step_name}=$p is not a valid software choice. \
Each step must be set to one of the following: none ${PREP_SOFTS[@]}";
				exit
			fi
		fi
		# DARTEL
		if [[ $p == ${DARTEL} ]]; then 
			if [[ ${NORM} != ${DARTEL} ]]; then
				echo "${label} ERROR: ${step_name}=${p} but NORM=${NORM}. \
In ${DARTEL}, NORM must always be used.";
				exit
			fi
			if [[ ${REALIGN} == ${DARTEL} ]] && [[ ${UNWARP} != 'none' ]]; 
			then echo "${label} ERROR: ${step_name}=${p} but UNWARP=${UNWARP}. \
In ${DARTEL}, if REALIGN is used, then UNWARP must be set to 'none'."
			exit
			fi
		fi
		i=$(($i + 1))
	done
	# FSL
	if [[ ${UNWARP} == ${FSL} ]] && [[ ${REALIGN} != ${FSL} ]]; then 
		echo "${label} ERROR: UNWARP=${UNWARP} but REALIGN=${REALIGN}. In ${FSL}, \
if UNWARP is used, then REALIGN must be as well. Aborting..."
		exit
	fi
	# SPM12w
	if [[ ${NORM} == ${SPMW} ]] && [[ ${REALIGN} != ${SPMW} ]]; then 
		echo "${label} ERROR: NORM=${NORM} but REALIGN=${REALIGN}. In ${SPMW}, if \
NORM is used, then REALIGN must be as well. Aborting..."
		exit
	fi

	# Create array based on order of used preprocessing software, such that:
	# 0 means the parameter uses a different software than the previous step
	# 1 means the parameter uses the same software as the previous step
	i=0; for p in "${step_softs[@]}"; do
		# check if current step is same as cur_soft (current software parameter)
		if [[ $p != 'none' ]]; then 
			if [[ $p == $cur_soft ]]; then sim_array[$i]=1; 
			else sim_array[$i]=0; 
			fi; 
			cur_soft=$p; 
		else 
			sim_array[$i]=1; 
		fi
		i=$(($i + 1))
	done
	sim_array[$i]=0
	# set first software choice to 1
	i=0; for p in "${step_softs[@]}"; do 
		if [[ $p != 'none' ]]; then sim_array[$i]=1; break; fi; 
		i=$(($i + 1)); 
	done

	# CREATE WORKING DIRECTORY IN PREP
	if [[ ! -d ${wd_dir_full} ]]; then mkdir ${wd_dir_full}; fi
	DATE=`date +%Y%m%d`
	cp ${PARS_DIR}/${parsfile} ${wd_dir_full}/${DATE}_${parsfile}


	# CREATE LIST OF SUBJECT IDS
	get_subs $t ${RAW_DIR}/$t ${PREP_DIR}/${t}/${wd_dir} "$@"

	if [[ -z $SUBS ]]; then 
		echo "${label} No subjects found for task $t. Moving on to next task..."; 
		continue; 
	fi

	# LIST STEPS THAT WILL BE RUN AND SAVE THEM TO THE TASK'S LOG FILE
	echo "${label}" | tee -a "$logfile_wd"
	echo "${label} $(date) *** Running subjects ${SUBS[@]} in task $t ***" | tee -a \
		"$logfile_wd"
	echo "${label} Slice Time Correction = $SLICE_TIME" | tee -a "$logfile_wd"
	echo "${label} Motion Correction     = $REALIGN" | tee -a "$logfile_wd"
	echo "${label} Unwarping             = $UNWARP" | tee -a "$logfile_wd"
	echo "${label} Normalization         = $NORM" | tee -a "$logfile_wd"
	echo "${label} Smoothing             = $SMOOTH_SOFT (kernel size: $SMOOTH)" | \
		tee -a "$logfile_wd"
	echo "${label} Bandpass Filter       = $FILTER (hpf: $hFilter, lpf: $lFilter)" | \
		tee -a "$logfile_wd"
	echo "${label}"
	echo "${label} Writing prep files to ${wd_dir_full}"
	
	# RUN SUBJECTS
	# Run each subject, one at a time
	n=0; for s in "${SUBS[@]}"; do
		echo "${label}"
		echo "${label} $(date) == beginning preprocessing of $s =="

		# CHECK IF SUBJ EXIST IN TSK
		# if subject does not exist, then exit
		if [[ -z $s ]]; then 
			echo "${label} WARNING: Can't find subject ${s}. Skipping...";
			continue; 
		fi

		first_step=1; prev_jobid=${first_jobid}

		# FILENAMES/PATHS FOR SUBJ
		wd_dir_sub=${wd_dir_full}/${s}
		logfile=${wd_dir_sub}/LOG.txt

		# SET UP SUBJ FOLDER IN PREP
		if ! ${keep_prep} && [[ -d "${wd_dir_sub}" ]]; then 
			# if -a flag was not used and the subject already exists, delete
			echo "${label} $(date) ${wd_dir_sub} already exists. Deleting..."\
				 | tee -a "${logfile_wd}"; 
			rm -rf ${wd_dir_sub}; 
		fi
		if [[ ! -d "${wd_dir_sub}" ]]; then 
			# copy sub folder from raw/tsk to prep/tsk/wd
			echo "${label} $(date) Copying ${s}'s raw folder to ${wd_dir_sub}..." | \
				tee -a "${logfile_wd}" 
			cp -r ${RAW_DIR}/${t}/${s} ${wd_dir_sub}
		else echo "${label} $(date) Using preprocessed data as raw" | tee -a "${logfile_wd}" "${logfile}"
		fi

		# empty all variables to start new with this subject
		reset_step_par; unset ext; unset pnames

		# GO THROUGH STEPS
		i=0; for p in "${step_softs[@]}"; do
			# SET UP PREPROCESING STEPS
			step_name=${step_names[$i]}; e=${step_exts[$i]}

			# if current step is set to 'none', skip and move on to next step
			if [[ $p != 'none' ]]; then 

				# check if current step NORM in DARTEL
				if [[ ${step_name} == 'NORM' ]] && [[ $NORM == ${DARTEL} ]]; then 
					# if not last subject, reset step par and ext
					if [[ $n -ne $((${#SUBS[@]} - 1)) ]]; then 
						reset_step_par; unset ext; 
					fi; 
					continue 2; 
				fi
				# add step extension to current software's extension list
				ext=${ext}${e}
				cur_soft=${p}
				pnames="${pnames} ${step_name}"

				# turn on step in step.par
				echo "${step_name}='${cur_soft}'" >> "$stepfile"
				echo "EPI_ACCEL=${EPI_ACCEL}" >> "$stepfile"
				echo "EPI_ECHOSPACING=${EPI_ECHOSPACING}" >> "$stepfile"
			fi
			# check if next step uses same software, if so, run steps
			if [[ ${sim_array[$((${i} + 1))]} -eq 0 ]]; then 

				# RUN STEP(S)

				# if all steps were set to none, skip to next task
				if [[ -z ${pnames} ]]; then  
					echo "${label} All steps set to 'none'. Moving on to next task..."
					echo "${label} WARNING: All steps set to 'none'" | tee -a $logfile_wd
					break 2
				fi

				# WRITE P_FILE
				# if first subject, write out pfile based on step.par
				if [[ $n -eq 0 ]]; then 
					bash ${SCRIPT_DIR_UTIL}/write_pfile \
						${cur_soft} ${t} ${ext}
				fi
				#script_path="${SCRIPT_DIR}/${cur_soft}"
				run_script="${script_path}/sbatch_prep_${cur_soft}"
				pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

				# RUN STEP/SUBMIT JOB

				# set run_time
				run_time=$((60 * ${#ext} + 500))
				# add an hour run if normalization is selected
				if [[ ${ext[@]} =~ w ]]; then
					add_time=$((60*$NRUNS)) 
					run_time=$((${run_time}+${add_time}))
				fi

				# make run_name for job
				run_name="${cur_soft}${ext}_prep_${s}"

				# move into software's script directory, quietly
				pushd ${script_path} > /dev/null   

				# submit job
				j='%j'
				tflag='-t=${run_time}'
				jflag="-J ${run_name}"
				oflag="--output=${OUT_DIR}/${run_name}-$j.out"
				dflag="--dependency=afterok:${prev_jobid}"
				flags="${!tflag} $oflag $jflag $mflag $dflag"
				prev_jobid=$(sbatch $flags "${run_script}" -p "$pfile" "$s" | grep -o '[0-9]*')
				# save/print jobid number
				jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames}\
 in ${cur_soft} for subject ${s}"
				echo "${jobinfo_str}" | tee -a "${logfile_wd}" "${logfile}"
				
				# Append job ID to list of job IDs DARTEL has to wait for
				all_jobs+=":${prev_jobid}"

				# return to the previous directory, quietly
				popd > /dev/null   

				# clear variables for next step
				reset_step_par; unset ext; first_step=0; unset pnames;
			fi
			# increase step index by one
			i=$(($i + 1))
		done
		# increase sub index by one
		n=$(($n + 1))
	done
	# setup dependency flag for DARTEL
	unset dependency_flag
	all_jobs=${all_jobs#:} # remove the leading : from all_jobs list for sbatch
	if [[ -n $all_jobs ]]; then 
		dependency_flag="--dependency=afterok:${all_jobs}"
	fi 

	# DARTEL
	# if normalization is run in DARTEL, run group
	if [[ $NORM == ${DARTEL} ]]; then
		echo "${label}"
		echo "${label} $(date) == beginning group preprocessing of ${SUBS[@]} =="

		# SET UP FOR DARTEL

		# set i to NORM index (second to last)
		i=$((${#step_softs[@]} - 3))  

		# store vars
		p=${step_softs[$i]}; step_name=${step_names[$i]}; e=${step_exts[$i]}

		# add step extension to current ext list and turn step on in step.par
		ext=${ext}${e}; cur_soft=${p}; pnames="${pnames} ${step_name}"
		echo "${step_name}='${p}'" >> "$stepfile"

		# if smoothing also uses DARTEL, add s to ext and turn on in step.par
		i=$(($i + 1)); 
		if [[ ${sim_array[$i]} -eq 1 ]] && [[ ${step_softs[$i]} != 'none' ]]; then
			step_name=${step_names[$i]}; e=${step_exts[$i]}; 
			ext=${ext}${e}; pnames="${pnames} $step_name"
			echo "${step_name}='$p'" >> "$stepfile"
		fi

		# RUN DARTEL

		# if few than 20 subs, DARTEL run_time = 48 hours, else run_time=72hrs
		if [[ ${#SUBS[@]} -le 20 ]]; then run_time=2880; else run_time=4320; fi

		# write pfile for DARETL
		bash ${SCRIPT_DIR_UTIL}/write_pfile ${cur_soft} ${t} ${ext}

		# path names
		run_script="${script_path}/sbatch_prep_${cur_soft}"
		pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

		# make run_name for job
		run_name="${cur_soft}${ext}_prep"

		# move into software's script directory, quietly
		pushd ${script_path} > /dev/null   	

		# submit job
		tflag='-t ${run_time}'
                jflag="-J ${run_name}"
		oflag="-o ${OUT_DIR}/${run_name}-%j.out"
		flags="${!tflag} $oflag $jflag $mflag"
                prev_jobid=$(sbatch ${flags} ${dependency_flag} "${run_script}" -p "$pfile" ${SUBS[@]} | grep -o '[0-9]*')
        dartel_jobid=${prev_jobid}
		# print jobid to console
		jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames} in \
${cur_soft} for subject(s) ${SUBS[@]}"
		echo ${jobinfo_str}

		# write to each sub's logfiles
		for s in "${SUBS[@]}"; do
			logfile=${wd_dir_full}/${s}/LOG.txt
			echo "${jobinfo_str}" >> "${logfile}"
		done

		# return to the previous directory, quietly
		popd > /dev/null



		if [[ ${sim_array[$i]} -ne 1 ]] || [[ ${sim_array[$(($i + 1))]} -ne 1 ]]; then


			if [[ $SMOOTH_SOFT == ${DARTEL} ]]; then
				step_softs=( "${step_softs[@]: -1}" )
				step_exts=( "${step_exts[@]: -1}" )
				step_names=( "${step_names[@]: -1}" )
				sim_array=( "${sim_array[@]: -2}" )
			else
				step_softs=( "${step_softs[@]: -2}" )
				step_exts=( "${step_exts[@]: -2}" )
				step_names=( "${step_names[@]: -2}" )
				sim_array=( "${sim_array[@]: -3}" )
				[[ $step_softs == 'none' ]] && sim_array[1]=1 
			fi
			n=0; for s in "${SUBS[@]}"; do
				echo "${label}"

				# unset variables
				reset_step_par; unset ext; unset pnames

				prev_jobid=${dartel_jobid}


				i=0; for p in "${step_softs[@]}"; do
					# SET UP PREPROCESING STEPS
					step_name=${step_names[$i]}; e=${step_exts[$i]}

					# if current step is set to 'none', skip and move on to next step
					if [[ $p != 'none' ]]; then 
						# add step extension to current software's extension list
						ext=${ext}${e}
						cur_soft=${p}
						pnames="${pnames} ${step_name}"

						# turn on step in step.par
						echo "${step_name}='${cur_soft}'" >> "$stepfile"
						echo "EPI_ACCEL=${EPI_ACCEL}" >> "$stepfile"
						echo "EPI_ECHOSPACING=${EPI_ECHOSPACING}" >> "$stepfile"
					fi
					# check if next step uses same software, if so, run steps
					if [[ ${sim_array[$((${i} + 1))]} -eq 0 ]]; then 

						# RUN STEP(S)

						# # if all steps were set to none, skip to next task
						# if [[ -z ${pnames} ]]; then  
						# 	echo "${label} All steps set to 'none'. Moving on to next task..."
						# 	echo "${label} WARNING: All steps set to 'none'" | tee -a $logfile_wd
						# 	break 2
						# fi

						# WRITE P_FILE
						# if first subject, write out pfile based on step.par
						if [[ $n -eq 0 ]]; then 
							bash ${SCRIPT_DIR_UTIL}/write_pfile \
								${cur_soft} ${t} ${ext}
						fi
						#script_path="${SCRIPT_DIR}/${cur_soft}"
						run_script="${script_path}/sbatch_prep_${cur_soft}"
						pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

						# RUN STEP/SUBMIT JOB

						# set run_time
						run_time=$((60 * ${#ext} + 500))
						# add an hour run if normalization is selected
						if [[ ${ext[@]} =~ w ]]; then
							add_time=$((60*$NRUNS)) 
							run_time=$((${run_time}+${add_time}))
						fi

						# make run_name for job
						run_name="${cur_soft}${ext}_prep_${s}"

						# move into software's script directory, quietly
						pushd ${script_path} > /dev/null   

						# submit job
						j='%j'
						tflag='-t=${run_time}'
						jflag="-J ${run_name}"
						oflag="--output=${OUT_DIR}/${run_name}-$j.out"
						dflag="--dependency=afterok:${prev_jobid}"
						flags="${!tflag} $oflag $jflag $mflag $dflag"
						prev_jobid=$(sbatch $flags "${run_script}" -p "$pfile" "$s" | grep -o '[0-9]*')
						# save/print jobid number
						jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames} \
in ${cur_soft} for subject ${s}"
						echo "${jobinfo_str}" | tee -a "${logfile_wd}"
						
						# Append job ID to list of job IDs DARTEL has to wait for
						all_jobs+=":${prev_jobid}"

						# return to the previous directory, quietly
						popd > /dev/null   

						# clear variables for next step
						reset_step_par; unset ext; first_step=0; unset pnames;
					fi
					# increase step index by one
					i=$(($i + 1))
				done
				# increase sub index by one
				n=$(($n + 1))
			done
		fi
	fi



	# 	# RUN SMOOTHING (iff not in DARTEL)
	# 	if [[ ${sim_array[$i]} -eq 0 ]]; then
	# 		n=0; for s in "${SUBS[@]}"; do
	# 			echo "${label}"

	# 			# unset variables
	# 			reset_step_par; unset ext; unset pnames

	# 			# assign variables for this step
	# 			p=${step_softs[$i]}
	# 			step_name=${step_names[$i]} 
	# 			e=${step_exts[$i]}
	# 			ext=${ext}${e}
	# 			cur_soft=$p
	# 			pnames="${pnames} $step_name"

	# 			# write step to step pars file
	# 			echo "${step_name}='$p'" >> "$stepfile"

	# 			# subject's log file
	# 			logfile=${wd_dir_full}/${s}/LOG.txt

	# 			# if first subject, write out pfile based on step.par
	# 			if [[ $n -eq 0 ]]; then 
	# 				bash ${SCRIPT_DIR_UTIL}/write_pfile \
	# 					${cur_soft} ${t} ${ext}
	# 			fi

	# 			# set paths to scripts/pfile for job
	# 			#script_path="${SCRIPT_DIR}/${cur_soft}"
	# 			run_script="${script_path}/sbatch_prep_${cur_soft}"
	# 			pfile="${script_path}/p_${cur_soft}_${t}${ext}.m"

	# 			# make run_name for job
 #                		run_name="${cur_soft}${ext}_prep_${s}"

	# 			# run job
	# 			pushd ${script_path} > /dev/null
	# 			tflag='-t 60'
	# 			jflag="-J ${run_name}"
	# 			oflag="-o ${OUT_DIR}/${run_name}-%j.out"
	# 			dflag="--dependency=afterok:${prev_jobid}"
	# 			flags="${!tflag} $oflag $jflag $mflag $dflag"
	# 	                prev_jobid=$(sbatch ${flags} "${run_script}" -p "$pfile" "${s}" | grep -o '[0-9]*')
	# 			jobinfo_str="${label} $(date) job ${prev_jobid} submitted to run${pnames}\
 # in ${cur_soft} for subject ${s}"
	# 			echo "${jobinfo_str}" | tee -a "${logfile_wd}"
	# 			popd > /dev/null

	# 			# increase sub index by one
	# 			n=$(($n + 1))
	# 		done
	# 	fi
	# fi

	# Write '[PREP] Done.' in each subject's LOG.txt file
	for s in "${SUBS[@]}"; do
		# iff the subject's folder exists
		if [[ -d ${wd_dir_full}/${s} ]]; then
			logfile=${wd_dir_full}/${s}/LOG.txt
			echo "${label} Done. $(date)" >> "$logfile"
		fi
	done

	# Write Done. to task logifle
	echo "${label}" | tee -a "${logfile_wd}"
	echo "${label} Done. $(date)" | tee -a "${logfile_wd}"
	echo "${label}" >> "${logfile_wd}"
done

